id: main
namespace: chi-traffic

inputs:
  - id: start_date
    type: DATETIME
    required: false
    displayName: "Backfill start date for load"

  - id: end_date
    type: DATETIME
    required: false
    displayName: "Backfill end date for load"

tasks:
  - id: validate_inputs
    type: io.kestra.plugin.scripts.python.Commands
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    warningOnStdErr: false
    beforeCommands:
      - echo "Running input validation..."
    commands:
      - > 
        python -c "import os; import sys; from datetime import datetime;
        start_date = os.getenv('START_DATE');
        end_date = os.getenv('END_DATE');

        if (start_date and not end_date) or (end_date and not start_date) :
            print('ERROR: Both start_date and end_date must be provided together.');
            sys.exit(1);
        elif start_date and end_date:
          start_date = datetime.strptime(start_date, '%Y-%m-%dT%H:%M:%S.000');
          end_date = datetime.strptime(end_date, '%Y-%m-%dT%H:%M:%S.000');
          
          if start_date >= end_date:
              print('ERROR: Start date must be before end date.');
              sys.exit(1);

        print('Validation passed: Inputs are either both provided or both empty.');"

  - id: workingDirectory
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
    - id: cloneRepository
      type: io.kestra.plugin.git.Clone
      url: https://github.com/alepanti/ChiTrafficInsights
      branch: main

    - id: getAPIdata
      type: io.kestra.plugin.scripts.python.Commands
      taskRunner:
        type: io.kestra.plugin.core.runner.Process
      env:
        GCS_BUCKET_NAME: "{{ kv('GCS_BUCKET_NAME') }}"
        CSV_FILE_PATH: "{{ kv('CSV_FILE_PATH') }}"
      warningOnStdErr: false
      beforeCommands:
        - pip install -r api_load/requirements.txt
        - export START_DATE="{{ inputs.start_date | date('yyyy-MM-dd\'T\'HH:mm:ss.SSS') }}"
        - export END_DATE="{{ inputs.end_date | date('yyyy-MM-dd\'T\'HH:mm:ss.SSS') }}"
      commands:
        - python api_load/api_load.py
    
    - id: loadBQ
      type: io.kestra.plugin.scripts.python.Commands
      taskRunner:
        type: io.kestra.plugin.core.runner.Process
      env:
        SOURCES__FILESYSTEM__BUCKET_URL: "{{ kv('GCS_URL')}}"
        SOURCES__FILESYSTEM__FILE_GLOB: "*.csv"
      warningOnStdErr: false
      beforeCommands:
        - pip install -r dlt_bq/requirements.txt
        - dlt --non-interactive init filesystem bigquery
        - rm .dlt/secrets.toml
      commands:
        - python dlt_bq/load_bq.py
      
    - id: dbtBuild
      type: io.kestra.plugin.dbt.cli.DbtCLI
      containerImage: ghcr.io/kestra-io/dbt-bigquery:latest
      taskRunner:
        type: io.kestra.plugin.scripts.runner.docker.Docker
      inputFiles:
        sa.json: "{{kv('GCP_CREDS')}}"
      env:
        DBT_DATABASE: "{{kv('GCP_PROJECT_ID')}}"
        DBT_SCHEMA: "{{kv('GCP_DATASET')}}"
        DBT_RAW_DATASET: "{{ kv('DBT_RAW_DATASET') }}"
        GOOGLE_APPLICATION_CREDENTIALS: sa.json
      namespaceFiles:
        enabled: true
      storeManifest:
        key: manifest.json
        namespace: "{{ flow.namespace }}"
      projectDir: ./dbt
      commands:
        - dbt deps --project-dir ./dbt
        - dbt build --project-dir ./dbt
      